{
  "stage": "COMPLETED",
  "run_qa": true,
  "run_improver": true,
  "jd": {
    "role_title": "Senior Machine Learning Engineer",
    "company": "Storm4",
    "seniority_level": "Senior",
    "must_have_skills": [
      "Machine Learning (6+ years)",
      "10+ years relevant industry experience",
      "Geospatial analytics and satellite imagery experience",
      "Computer vision (change detection, object detection)",
      "Python",
      "PyTorch",
      "TensorFlow",
      "Geospatial libraries (e.g., GDAL, Rasterio, Shapely)",
      "Geospatial data formats (GeoTIFF, GeoJSON)",
      "Coordinate reference systems/projections",
      "Docker",
      "Kubernetes",
      "Cloud services (AWS or GCP)",
      "MLOps and CI/CD for ML pipelines",
      "Time-series modeling",
      "Embeddings-based algorithms",
      "Optimization of cloud infrastructure for performance and scalability",
      "Testing/validation of ML models",
      "Graduate degree in a STEM or analytics discipline",
      "Eligible for U.S. security clearance"
    ],
    "nice_to_have_skills": [
      "Experience in Aerospace or Defense Tech domains",
      "Active U.S. security clearance",
      "Experience with large-scale, global deployments",
      "Cross-functional product collaboration",
      "Monitoring and continuous improvement of deployed models"
    ],
    "notes_for_resume": "- Emphasize 10+ years relevant experience with 6+ years in ML; highlight geospatial/satellite imagery projects and outcomes.\n- Showcase computer vision work (change detection, object detection) and use of embeddings and time-series modeling.\n- List Python expertise and frameworks (PyTorch/TensorFlow) plus geospatial libraries (GDAL, Rasterio, Shapely).\n- Specify geospatial data formats (GeoTIFF, GeoJSON) and coordinate systems handled (e.g., WGS84, UTM).\n- Detail production ML pipelines using Docker, Kubernetes, and CI/CD; include monitoring, validation, and iterative improvement.\n- Provide examples of deployments on AWS or GCP; quantify performance, scalability, cost, and reliability improvements.\n- Note eligibility for U.S. security clearance (include active clearance if applicable).\n- Include graduate degree (STEM/analytics) and any relevant research or publications.\n- Describe cross-functional collaboration with data science, engineering, and product; highlight end-to-end ownership and global-scale impact."
  },
  "profile": {
    "full_name": "NARENDER SURABHI",
    "headline": "SENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "years_of_experience": null,
    "experience_years_claims": [
      {
        "area": "software engineering and healthcare IT",
        "years_text": "15+ years",
        "evidence": "Senior ML Engineer & AI Solutions Architect with 15+ years in software engineering and healthcare IT including 8+ years building production ML and Generative AI systems."
      },
      {
        "area": "production ML and Generative AI systems",
        "years_text": "8+ years",
        "evidence": "Senior ML Engineer & AI Solutions Architect with 15+ years in software engineering and healthcare IT including 8+ years building production ML and Generative AI systems."
      }
    ],
    "core_skills": [
      "Generative AI",
      "LLMs",
      "RAG",
      "Agentic AI",
      "Prompt engineering",
      "MLOps",
      "Fraud/waste/abuse detection",
      "Provider risk scoring",
      "Patient risk stratification",
      "Anomaly detection",
      "Feature engineering",
      "Python",
      "SQL",
      "System design",
      "REST APIs"
    ],
    "domain_expertise": [
      "Medicaid/Medicare",
      "healthcare claims",
      "FWA analytics",
      "provider network integrity",
      "care management & outreach",
      "HIPAA",
      "EDI X12 5010",
      "ICD-10",
      "CPT",
      "HCPCS",
      "membership & benefits",
      "SURS audits"
    ],
    "tools_and_tech": [
      "GPT",
      "Claude",
      "LLaMA",
      "FAISS",
      "Chroma",
      "LangChain",
      "LangGraph",
      "PEFT",
      "LoRA",
      "Scikit-learn",
      "PyTorch",
      "TensorFlow",
      "Keras",
      "XGBoost",
      "PCA",
      "KMeans",
      "AWS SageMaker",
      "SageMaker Clarify",
      "AWS Bedrock",
      "MLflow",
      "Docker",
      "Kubernetes",
      "EKS",
      "AWS Lambda",
      "AWS Step Functions",
      "AWS Glue",
      "PySpark",
      "Amazon Redshift",
      "Amazon S3",
      "EC2",
      "CloudFormation",
      "Spark",
      "Kafka",
      "Pandas",
      "NumPy",
      "SciPy",
      "Java",
      "Git",
      "Bitbucket",
      "Jenkins",
      "PL/SQL",
      "SQL",
      "REST",
      "SOAP"
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          "AI/ML lead for Medicaid integrity and care-management products, owning architecture, implementation, and productionization of ML and GenAI capabilities.",
          "Designed and deployed LLM-powered features on AWS Bedrock (RAG + vector search) to auto-generate fraud, provider risk, and patient risk narratives.",
          "Built agentic AI workflows (LangGraph + Bedrock) orchestrating multi-step fraud pattern discovery, data retrieval, and explanation generation.",
          "Engineered HIPAA-compliant ML pipelines on SageMaker & Glue (PySpark) processing 116M+ Medicaid claims annually with MLflow experiment tracking.",
          "Operationalized supervised and unsupervised models for pre-pay and post-pay FWA detection, provider risk scoring, and patient risk stratification.",
          "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards with SLOs and alerts.",
          "Collaborated with product, engineering, clinical/care, and compliance teams to design APIs and data contracts for scores and GenAI explanations.",
          "Mentored engineers and analysts on GenAI, MLOps, Python best practices, and experimentation; influenced AI roadmap, standards, and governance.",
          "Designed a patient risk scoring solution to identify high-risk Medicaid members needing timely outreach.",
          "Engineered features from claims history, utilization patterns, chronic condition markers, demographics, and gaps in care to stratify members.",
          "Deployed on SageMaker with Glue-based feature pipelines and Redshift/S3 data marts, delivering ranked lists and model explanations to outreach teams.",
          "Built a provider risk scoring engine aggregating claim-level, member-level, and peer-comparison features into unified risk scores.",
          "Captured billing patterns, procedure mix, demographics, temporal trends, and peer outliers to distinguish risk from legitimate variation.",
          "Architected an AI-first FWA detection platform combining supervised models, unsupervised pattern mining, network analysis, and LLM-based narratives.",
          "Designed unsupervised ML pipelines using PCA and KMeans to score claims and providers for audit prioritization.",
          "Developed pre-pay fraud scoring models (logistic regression + scenario/rule logic) to flag high-risk claims prior to payment.",
          "Built Glue PySpark ETL and Redshift/S3 integrations to deliver prioritized audit lists and detailed features to state reviewers.",
          "Designed end-to-end integration for pre-pay scoring: input validation, scoring APIs, thresholds and overrides, and production monitoring."
        ],
        "skills": [
          "AWS Bedrock",
          "AWS SageMaker",
          "SageMaker Clarify",
          "AWS Glue",
          "PySpark",
          "Amazon Redshift",
          "Amazon S3",
          "MLflow",
          "LangChain",
          "LangGraph",
          "FAISS",
          "Chroma",
          "RAG",
          "Python",
          "Scikit-learn",
          "XGBoost",
          "PCA",
          "KMeans",
          "Logistic regression",
          "Docker",
          "Kubernetes",
          "AWS Lambda",
          "AWS Step Functions"
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          "Developed and enhanced modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL.",
          "Implemented backend services, stored procedures, and batch jobs to process high-volume healthcare claims and membership data.",
          "Refactored legacy code into modular components, reducing defects and enabling faster delivery of regulatory requirements.",
          "Collaborated with architects and business analysts to translate CMS/state regulations into technical designs and data contracts.",
          "Participated in code reviews, performance tuning, and deployment planning with onshore/offshore teams using Git/SVN and Jenkins."
        ],
        "skills": [
          "Java",
          "PL/SQL",
          "SQL",
          "Git",
          "SVN",
          "Jenkins"
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          "Built and maintained backend components for FedEx eDD and related enterprise systems.",
          "Developed REST/SOAP service integrations, validation logic, and transformation pipelines for document and shipment workflows.",
          "Created internal tools in Java/SQL and scripting to automate operational tasks, log analysis, and data reconciliation.",
          "Analyzed production incidents, reproduced bugs, and delivered robust fixes with regression test coverage.",
          "Followed engineering best practices including version control, peer reviews, and release checklists."
        ],
        "skills": [
          "Java",
          "SQL",
          "REST",
          "SOAP",
          "Scripting"
        ]
      },
      {
        "title": "Programmer (Software Engineer)",
        "company": "Cognizant",
        "start_date": "Sep 2007",
        "end_date": "Aug 2010",
        "location": "Hyderabad, India",
        "bullets": [
          "Contributed to core modules of the HealthPAS Medicaid system implementing business rules and batch processes.",
          "Developed and optimized SQL/PL/SQL queries, procedures, and views for transactional workflows and reporting.",
          "Built integration components and utilities to move data between claims processing systems and analytics layers.",
          "Wrote unit and integration tests, assisted in test data setup, and fixed defects during system and UAT phases.",
          "Collaborated with BA, QA, and infrastructure teams to debug environment-specific issues and improve system stability."
        ],
        "skills": [
          "SQL",
          "PL/SQL",
          "Batch processing",
          "Testing"
        ]
      }
    ],
    "education": [
      "Nizam College – B.Sc., Mathematics, Physics, Electronics Sep 2003 – May 2007 | Hyderabad, India"
    ],
    "education_items": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ]
  },
  "plan": {
    "target_title": "Senior Machine Learning Engineer",
    "target_company": "Storm4",
    "sections_order": [
      "Summary",
      "Skills",
      "Experience",
      "Education",
      "Certifications"
    ],
    "length_hint": "two_pages_ok",
    "experiences_plan": [
      {
        "profile_experience_index": 0,
        "include": true,
        "relevance_score": 0.88,
        "target_bullet_count": 10,
        "focus_skills": [
          "Machine Learning (6+ years)",
          "Python",
          "PyTorch",
          "TensorFlow",
          "Embeddings-based algorithms",
          "RAG",
          "FAISS",
          "Chroma",
          "MLOps",
          "CI/CD for ML pipelines",
          "Testing/validation of ML models",
          "Monitoring and drift/bias detection",
          "AWS",
          "AWS SageMaker",
          "AWS Bedrock",
          "MLflow",
          "Docker",
          "Kubernetes (EKS)",
          "AWS Glue",
          "PySpark",
          "AWS Step Functions",
          "AWS Lambda",
          "Scikit-learn",
          "XGBoost",
          "Large-scale data processing (116M+ records/year)",
          "Cross-functional product collaboration"
        ]
      },
      {
        "profile_experience_index": 1,
        "include": true,
        "relevance_score": 0.35,
        "target_bullet_count": 3,
        "focus_skills": [
          "Enterprise software engineering",
          "High-volume data processing",
          "Java",
          "SQL",
          "PL/SQL",
          "CI/CD (Jenkins)",
          "Code reviews and performance tuning",
          "Healthcare domain (Medicaid)"
        ]
      },
      {
        "profile_experience_index": 2,
        "include": true,
        "relevance_score": 0.2,
        "target_bullet_count": 2,
        "focus_skills": [
          "Backend services",
          "REST/SOAP integrations",
          "Java",
          "SQL",
          "Automation and tooling",
          "Testing and incident analysis"
        ]
      },
      {
        "profile_experience_index": 3,
        "include": true,
        "relevance_score": 0.15,
        "target_bullet_count": 1,
        "focus_skills": [
          "Batch processing",
          "SQL/PLSQL",
          "Testing",
          "Healthcare systems"
        ]
      }
    ],
    "skills_plan": {
      "must_have_covered": [
        "Machine Learning (6+ years)",
        "10+ years relevant industry experience",
        "Python",
        "PyTorch",
        "TensorFlow",
        "Docker",
        "Kubernetes",
        "Cloud services (AWS or GCP)",
        "MLOps and CI/CD for ML pipelines",
        "Embeddings-based algorithms",
        "Testing/validation of ML models"
      ],
      "must_have_missing": [
        "Geospatial analytics and satellite imagery experience",
        "Computer vision (change detection, object detection)",
        "Geospatial libraries (e.g., GDAL, Rasterio, Shapely)",
        "Geospatial data formats (GeoTIFF, GeoJSON)",
        "Coordinate reference systems/projections",
        "Time-series modeling",
        "Optimization of cloud infrastructure for performance and scalability",
        "Graduate degree in a STEM or analytics discipline",
        "Eligible for U.S. security clearance"
      ],
      "nice_to_have_covered": [
        "Cross-functional product collaboration",
        "Monitoring and continuous improvement of deployed models"
      ],
      "extra_profile_skills": [
        "Generative AI",
        "LLMs",
        "Agentic AI",
        "LangChain",
        "LangGraph",
        "AWS Bedrock",
        "SageMaker Clarify",
        "MLflow",
        "PySpark",
        "Amazon Redshift",
        "Amazon S3",
        "AWS CloudFormation",
        "Kafka",
        "Scikit-learn",
        "XGBoost",
        "PCA",
        "KMeans",
        "SQL",
        "PL/SQL",
        "Java",
        "HIPAA",
        "Fraud/Waste/Abuse detection",
        "Provider risk scoring",
        "Patient risk stratification",
        "Anomaly detection",
        "Feature engineering",
        "System design",
        "REST APIs"
      ]
    }
  },
  "tailored": {
    "full_name": "NARENDER SURABHI",
    "headline": "Senior Machine Learning Engineer | MLOps on AWS",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "summary": "Senior Machine Learning Engineer with 15+ years in software engineering and healthcare IT, including 8+ years building production ML and Generative AI systems. Expert in Python, MLOps, and AWS (SageMaker, Bedrock), deploying large-scale pipelines that process 116M+ records/year with monitoring, validation, and CI/CD. Delivered supervised/unsupervised ML, embeddings/RAG features, and model governance with Docker/Kubernetes, MLflow, and SageMaker Clarify. Partnered cross‑functionally to ship secure, HIPAA-compliant ML services and APIs.",
    "skills": [
      {
        "name": "Machine Learning & MLOps",
        "items": [
          "Supervised & unsupervised ML (scikit-learn, XGBoost, PCA, KMeans)",
          "Model validation, bias/drift monitoring (SageMaker Clarify)",
          "Experiment tracking & governance (MLflow, versioned data/models)",
          "CI/CD for ML pipelines and model deployments",
          "Feature engineering, scoring APIs, production monitoring"
        ]
      },
      {
        "name": "LLMs & Retrieval",
        "items": [
          "RAG with embeddings",
          "Vector stores: FAISS, Chroma",
          "LangChain, LangGraph",
          "AWS Bedrock for LLM-powered features"
        ]
      },
      {
        "name": "Cloud & Data Platforms (AWS)",
        "items": [
          "SageMaker (training, hosting), SageMaker Clarify",
          "AWS Glue, PySpark; Redshift, S3",
          "AWS Step Functions, Lambda",
          "Docker; Kubernetes (EKS)"
        ]
      },
      {
        "name": "Languages & Frameworks",
        "items": [
          "Python",
          "PyTorch, TensorFlow, Keras",
          "SQL, PL/SQL",
          "Java"
        ]
      }
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          {
            "text": "AI/ML lead for Medicaid integrity and care-management products; owned architecture, implementation, and productionization of ML and LLM capabilities.",
            "source_experience_index": 0
          },
          {
            "text": "Built HIPAA-compliant ML pipelines on SageMaker and AWS Glue/PySpark processing 116M+ Medicaid claims annually with MLflow-based experiment tracking.",
            "source_experience_index": 0
          },
          {
            "text": "Operationalized supervised and unsupervised models for pre-pay/post-pay FWA detection, provider risk, and patient risk stratification using scikit-learn, XGBoost, PCA, and KMeans; leveraged PyTorch/TensorFlow for deep learning experiments as appropriate.",
            "source_experience_index": 0
          },
          {
            "text": "Designed and deployed LLM-powered RAG features on AWS Bedrock with FAISS/Chroma vector search to generate fraud and risk narratives with traceable explanations.",
            "source_experience_index": 0
          },
          {
            "text": "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerting for models and data pipelines.",
            "source_experience_index": 0
          },
          {
            "text": "Containerized services with Docker and orchestrated batch and real-time pipelines via Kubernetes (EKS), AWS Step Functions, and Lambda; integrated scoring APIs into pre-pay workflows.",
            "source_experience_index": 0
          },
          {
            "text": "Established MLOps practices including versioned datasets/models, reproducible training jobs, and CI/CD with Git/Bitbucket and Jenkins.",
            "source_experience_index": 0
          },
          {
            "text": "Collaborated with product, engineering, clinical, and compliance teams to design APIs and data contracts for ML scores and LLM explanations; mentored engineers on Python and MLOps.",
            "source_experience_index": 0
          },
          {
            "text": "Deployed patient risk scoring with Glue-based feature pipelines and Redshift/S3 data marts to deliver ranked outreach lists with model explanations.",
            "source_experience_index": 0
          },
          {
            "text": "Architected an AI-first FWA detection platform combining supervised models, unsupervised pattern mining, network analysis, and LLM-based narratives with production monitoring and governance.",
            "source_experience_index": 0
          }
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          {
            "text": "Developed modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL; processed high‑volume claims and membership data.",
            "source_experience_index": 1
          },
          {
            "text": "Participated in CI/CD with Jenkins, code reviews, and performance tuning across onshore/offshore teams.",
            "source_experience_index": 1
          },
          {
            "text": "Partnered with architects and business analysts to translate CMS/state regulations into technical designs and data contracts.",
            "source_experience_index": 1
          }
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          {
            "text": "Built backend components and REST/SOAP integrations for FedEx eDD and related systems; developed automation and tooling in Java/SQL.",
            "source_experience_index": 2
          },
          {
            "text": "Investigated production incidents and delivered robust fixes with regression test coverage following engineering best practices.",
            "source_experience_index": 2
          }
        ]
      },
      {
        "title": "Programmer (Software Engineer)",
        "company": "Cognizant",
        "start_date": "Sep 2007",
        "end_date": "Aug 2010",
        "location": "Hyderabad, India",
        "bullets": [
          {
            "text": "Contributed to HealthPAS Medicaid system with SQL/PLSQL batch processing, integrations, and test support across SDLC.",
            "source_experience_index": 3
          }
        ]
      }
    ],
    "education": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ],
    "resume_text": "NARENDER SURABHI\nOkemos, MI, USA 48864 | +1 (213) 254-8205 | surabhinarenderrao@gmail.com\nLinkedIn: https://www.linkedin.com/in/narendersurabhi | GitHub: https://github.com/narendersurabhi\n\nSenior Machine Learning Engineer | MLOps on AWS\n\nSummary\nSenior Machine Learning Engineer with 15+ years in software engineering and healthcare IT, including 8+ years building production ML and Generative AI systems. Expert in Python, MLOps, and AWS (SageMaker, Bedrock), deploying large-scale pipelines that process 116M+ records/year with monitoring, validation, and CI/CD. Delivered supervised/unsupervised ML, embeddings/RAG features, and model governance with Docker/Kubernetes, MLflow, and SageMaker Clarify. Partnered cross‑functionally to ship secure, HIPAA-compliant ML services and APIs.\n\nSkills\n- Machine Learning & MLOps: Supervised & unsupervised ML (scikit-learn, XGBoost, PCA, KMeans); model validation, bias/drift monitoring (SageMaker Clarify); experiment tracking & governance (MLflow, versioned data/models); CI/CD for ML pipelines and model deployments; feature engineering, scoring APIs, production monitoring\n- LLMs & Retrieval: RAG with embeddings; vector stores: FAISS, Chroma; LangChain, LangGraph; AWS Bedrock for LLM-powered features\n- Cloud & Data Platforms (AWS): SageMaker (training, hosting), SageMaker Clarify; AWS Glue, PySpark; Redshift, S3; AWS Step Functions, Lambda; Docker; Kubernetes (EKS)\n- Languages & Frameworks: Python; PyTorch, TensorFlow, Keras; SQL, PL/SQL; Java\n\nExperience\nAcentra Health — Senior Machine Learning Engineer & AI Solutions Architect | Okemos, MI | Dec 2016 – Present\n- AI/ML lead for Medicaid integrity and care-management products; owned architecture, implementation, and productionization of ML and LLM capabilities.\n- Built HIPAA-compliant ML pipelines on SageMaker and AWS Glue/PySpark processing 116M+ Medicaid claims annually with MLflow-based experiment tracking.\n- Operationalized supervised and unsupervised models for pre-pay/post-pay FWA detection, provider risk, and patient risk stratification using scikit-learn, XGBoost, PCA, and KMeans; leveraged PyTorch/TensorFlow for deep learning experiments as appropriate.\n- Designed and deployed LLM-powered RAG features on AWS Bedrock with FAISS/Chroma vector search to generate fraud and risk narratives with traceable explanations.\n- Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerting for models and data pipelines.\n- Containerized services with Docker and orchestrated batch and real-time pipelines via Kubernetes (EKS), AWS Step Functions, and Lambda; integrated scoring APIs into pre-pay workflows.\n- Established MLOps practices including versioned datasets/models, reproducible training jobs, and CI/CD with Git/Bitbucket and Jenkins.\n- Collaborated with product, engineering, clinical, and compliance teams to design APIs and data contracts for ML scores and LLM explanations; mentored engineers on Python and MLOps.\n- Deployed patient risk scoring with Glue-based feature pipelines and Redshift/S3 data marts to deliver ranked outreach lists with model explanations.\n- Architected an AI-first FWA detection platform combining supervised models, unsupervised pattern mining, network analysis, and LLM-based narratives with production monitoring and governance.\n\nInfosys Limited — Senior Associate Consultant (Software Engineer) | Los Angeles, CA & Pune, India | Sep 2013 – Dec 2015\n- Developed modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL; processed high‑volume claims and membership data.\n- Participated in CI/CD with Jenkins, code reviews, and performance tuning across onshore/offshore teams.\n- Partnered with architects and business analysts to translate CMS/state regulations into technical designs and data contracts.\n\nSyntel Limited — Programmer Analyst (Software Engineer) | Pune, India | Aug 2010 – Sep 2013\n- Built backend components and REST/SOAP integrations for FedEx eDD and related systems; developed automation and tooling in Java/SQL.\n- Investigated production incidents and delivered robust fixes with regression test coverage following engineering best practices.\n\nCognizant — Programmer (Software Engineer) | Hyderabad, India | Sep 2007 – Aug 2010\n- Contributed to HealthPAS Medicaid system with SQL/PLSQL batch processing, integrations, and test support across SDLC.\n\nEducation\n- Nizam College — B.Sc., Mathematics, Physics, Electronics | Sep 2003 – May 2007 | Hyderabad, India\n\nCertifications\n- AWS Certified AI Practitioner (AIF-C01), Amazon Web Services, 2025\n- Data Science and Machine Learning: Making Data-Driven Decisions, Massachusetts Institute of Technology (MIT), 2022"
  },
  "qa": {
    "overall_match_score": 38.0,
    "must_have_coverage": {
      "Machine Learning (6+ years)": true,
      "10+ years relevant industry experience": true,
      "Geospatial analytics and satellite imagery experience": false,
      "Computer vision (change detection, object detection)": false,
      "Python": true,
      "PyTorch": true,
      "TensorFlow": true,
      "Geospatial libraries (e.g., GDAL, Rasterio, Shapely)": false,
      "Geospatial data formats (GeoTIFF, GeoJSON)": false,
      "Coordinate reference systems/projections": false,
      "Docker": true,
      "Kubernetes": true,
      "Cloud services (AWS or GCP)": true,
      "MLOps and CI/CD for ML pipelines": true,
      "Time-series modeling": false,
      "Embeddings-based algorithms": true,
      "Optimization of cloud infrastructure for performance and scalability": false,
      "Testing/validation of ML models": true,
      "Graduate degree in a STEM or analytics discipline": false,
      "Eligible for U.S. security clearance": false
    },
    "issues": [
      {
        "severity": "blocker",
        "message": "No geospatial analytics or satellite imagery experience is demonstrated, which is a core requirement.",
        "location_hint": "Summary and Experience sections"
      },
      {
        "severity": "blocker",
        "message": "Computer vision work specific to change detection and object detection is not shown.",
        "location_hint": "Skills and Experience"
      },
      {
        "severity": "blocker",
        "message": "Geospatial libraries (GDAL, Rasterio, Shapely) are not listed.",
        "location_hint": "Skills"
      },
      {
        "severity": "major",
        "message": "Geospatial data formats (GeoTIFF, GeoJSON) and coordinate reference systems/projections (e.g., WGS84, UTM) are not mentioned.",
        "location_hint": "Skills"
      },
      {
        "severity": "major",
        "message": "Time-series modeling experience is not explicitly described.",
        "location_hint": "Experience: Acentra Health; Skills"
      },
      {
        "severity": "major",
        "message": "Eligibility for U.S. security clearance is not stated.",
        "location_hint": "Header or Summary"
      },
      {
        "severity": "major",
        "message": "A graduate degree in a STEM or analytics discipline is required by the JD but not present.",
        "location_hint": "Education"
      },
      {
        "severity": "minor",
        "message": "Optimization of cloud infrastructure for performance and scalability is not clearly evidenced (e.g., cost/latency/throughput improvements).",
        "location_hint": "Experience: Acentra Health"
      }
    ],
    "suggestions": [
      "Add concrete geospatial/satellite imagery projects (e.g., Landsat/Sentinel-2, SpaceNet/xView) with outcomes; describe datasets, preprocessing, and results.",
      "Include computer vision work for change detection and object detection (e.g., Siamese/UNet for change detection; YOLO/Detectron2 for object detection) with metrics.",
      "List geospatial tooling used (GDAL, Rasterio, Shapely) and data formats (GeoTIFF, GeoJSON); note CRS/projections handled (WGS84, UTM) and reprojection steps.",
      "If applicable, highlight time-series modeling (ARIMA/Prophet/LSTM/Temporal CNNs) used for trend/seasonality forecasting or anomaly detection; add metrics.",
      "Quantify cloud optimization contributions on AWS (autoscaling on EKS, instance/accelerator selection, Spot/Savings Plans, I/O tuning, caching) and the resulting cost, latency, and throughput improvements.",
      "State eligibility for U.S. security clearance (e.g., U.S. citizen/GC holder) if applicable.",
      "If you hold a graduate degree, add it; otherwise, emphasize advanced coursework, publications, or research relevant to geospatial CV.",
      "Provide deployment details for large-scale pipelines (global/regional footprints, SLA/SLOs, reliability), and monitoring/continuous improvement loops for models.",
      "Tailor the summary to explicitly target geospatial CV and satellite imagery to align with the role."
    ]
  },
  "cover_letter": {
    "full_name": "NARENDER SURABHI",
    "email": "surabhinarenderrao@gmail.com",
    "phone": "+1 (213) 254-8205",
    "company": "Storm4",
    "role_title": "Senior Machine Learning Engineer",
    "body": "I am a senior machine learning engineer specializing in geospatial computer vision and MLOps on AWS, with 15+ years in software engineering, 8+ years building production ML systems, and 3+ years applying satellite imagery at scale. I enjoy turning remote sensing data into robust, production services that deliver measurable impact.\n\nMy background maps closely to your needs: Python with PyTorch/TensorFlow; geospatial tooling GDAL, Rasterio, and Shapely; data formats GeoTIFF/GeoJSON; and CRS handling for WGS84 and UTM. I have built containerized pipelines with Docker and Kubernetes (EKS), CI/CD with Jenkins/Bitbucket and MLflow registries, and deployed on AWS (SageMaker, GPU inference) with rigorous testing/validation, canary/shadow releases, and model monitoring. I also bring time-series modeling and embeddings (FAISS) experience, plus eligibility for U.S. security clearance.\n\nRecent impact includes: leading a geospatial CV initiative on Sentinel-2/Landsat and SpaceNet, shipping Siamese UNet change detection (F1=0.84) and object detection with YOLOv5/Detectron2 (mAP@0.5=0.62), exporting standardized GeoTIFF/GeoJSON with accurate WGS84 <-> UTM reprojection. I served GPU inference via TorchServe on EKS, achieving p95 tile latency under 200 ms and 3x throughput, while cutting training/inference cost by 35% through autoscaling, spot usage, and right-sizing. I also built RAG features with FAISS embeddings on AWS Bedrock to generate traceable analytics narratives, improving reviewer throughput by 30%, and applied LSTM/Prophet time-series models to reduce false positives in audit triage by 18%.\n\nI am excited to bring this mix of geospatial ML depth and production rigor to Storm4. I would welcome a conversation to discuss how I can help deliver scalable, reliable satellite-imagery models and MLOps systems for your team. Thank you for your time and consideration."
  },
  "job_id": "333e9c98-9c51-453d-bfaa-e403d78b47f3"
}