{
  "stage": "COMPLETED",
  "run_qa": true,
  "run_improver": true,
  "jd": {
    "role_title": "Senior Machine Learning Engineer, Applied AI",
    "company": "Block",
    "seniority_level": "Senior",
    "must_have_skills": [
      "Machine learning engineering (8+ years)",
      "Large Language Models (LLMs)",
      "Generative AI product development",
      "LLM fine-tuning and integration",
      "Scalable ML systems design and deployment",
      "MLOps (training, evaluation, CI/CD, monitoring, productionizing models)",
      "Cloud platforms (AWS/GCP/Azure) for high-scale production",
      "Building and shipping customer-facing ML features",
      "Data gathering and pipeline development for ML",
      "Automation of customer support workflows"
    ],
    "nice_to_have_skills": [
      "Retrieval-Augmented Generation (RAG)",
      "Knowledge distillation",
      "Prompt orchestration / prompt engineering",
      "Multi-tenant generative AI systems across business units",
      "Platform engineering for internal developer customers",
      "Mentorship and technical leadership",
      "Experimentation and A/B testing for ML features",
      "LLM evaluation techniques and guardrails",
      "Strong cross-functional communication"
    ],
    "notes_for_resume": "- Emphasize 8+ years of end-to-end ML engineering with examples of shipping customer-facing ML products and measurable business impact.\n- Showcase LLM work: fine-tuning/integration, prompt strategies, and any RAG or distillation you have used; include model evaluation and monitoring details.\n- Highlight projects automating customer support (chatbots, agent assist, case routing, knowledge retrieval, summarization) with metrics (deflection rate, CSAT, handle time reduction).\n- Detail scalable ML systems on major clouds (AWS/GCP/Azure), including production services, CI/CD, observability, and cost/performance optimizations.\n- Describe full ML lifecycle ownership: data collection, training, offline/online evaluation, deployment, and on-call/monitoring practices.\n- Mention building platform capabilities for internal developers and solutions that scale across multiple products/business units.\n- Include examples of rapid MVPs iterated into stable products, demonstrating pragmatic problem solving.\n- Note mentorship, technical documentation, and participation in design reviews to raise engineering standards."
  },
  "profile": {
    "full_name": "NARENDER SURABHI",
    "headline": "SENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "years_of_experience": 18.3,
    "core_skills": [
      "Machine learning engineering",
      "Generative AI",
      "Large language models (LLMs)",
      "Retrieval-augmented generation (RAG)",
      "Agentic AI and tool use",
      "MLOps",
      "Risk analytics (FWA, provider, patient)",
      "Feature engineering",
      "Model deployment (batch and real-time)",
      "Model monitoring and observability",
      "Prompt engineering",
      "HIPAA-compliant data architectures",
      "Anomaly detection",
      "Classification and regression",
      "Clustering"
    ],
    "domain_expertise": [
      "Medicaid/Medicare",
      "Healthcare claims",
      "FWA analytics",
      "Provider network integrity",
      "Care management & outreach",
      "HIPAA",
      "EDI X12 5010",
      "ICD-10",
      "CPT",
      "HCPCS",
      "Membership & benefits",
      "SURS audits"
    ],
    "tools_and_tech": [
      "AWS SageMaker",
      "AWS Bedrock",
      "SageMaker Clarify",
      "MLflow",
      "AWS Glue",
      "PySpark",
      "Amazon Redshift",
      "Amazon S3",
      "Amazon EC2",
      "AWS CloudFormation",
      "AWS Lambda",
      "AWS Step Functions",
      "Docker",
      "Kubernetes",
      "EKS",
      "Spark",
      "Kafka",
      "Python",
      "Pandas",
      "NumPy",
      "SciPy",
      "SQL",
      "Java",
      "scikit-learn",
      "PyTorch",
      "TensorFlow",
      "Keras",
      "XGBoost",
      "Logistic regression",
      "PCA",
      "KMeans",
      "FAISS",
      "Chroma",
      "LangChain",
      "LangGraph",
      "REST APIs",
      "Git",
      "Bitbucket",
      "Jenkins"
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          "Led AI/ML for Medicaid integrity and care-management products, owning architecture, implementation, and productionization of ML and GenAI features.",
          "Designed and deployed LLM-powered RAG features on AWS Bedrock to generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.",
          "Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, data retrieval, and explanation generation to surface emerging FWA schemes.",
          "Engineered HIPAA-compliant ML pipelines on SageMaker and Glue (PySpark) processing 116M+ Medicaid claims annually with MLflow-based experiment tracking.",
          "Operationalized supervised and unsupervised models for pre-pay and post-pay FWA detection, provider risk scoring, and patient risk stratification with batch and real-time endpoints.",
          "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts to meet accuracy and latency targets.",
          "Designed APIs and data contracts exposing scores, risk tiers, and GenAI explanations to downstream SIU, audit, and care-management systems.",
          "Mentored engineers and analysts on GenAI, MLOps, Python best practices, and experimentation; contributed to AI roadmap, standards, and governance.",
          "Patient Risk Scoring: Engineered features from claims, utilization, chronic conditions, demographics, and care gaps; deployed on SageMaker with Glue pipelines and Redshift/S3 data marts.",
          "Provider Risk Scoring: Built provider/group risk models using claim/member/peer-comparison features; integrated into Program Intelligence and SIU workflows.",
          "Program Intelligence: Architected platform combining supervised models, unsupervised pattern mining, network analysis, and LLM narratives for statewide FWA detection.",
          "AuditStudio (ND): Delivered unsupervised PCA and KMeans pipelines with Glue/Redshift/S3 to prioritize post-pay audits.",
          "ClaimsSure: Developed real-time pre-pay fraud scoring (logistic regression + rules) with scoring APIs, thresholds/overrides, and production monitoring."
        ],
        "skills": [
          "AWS Bedrock",
          "AWS SageMaker",
          "AWS Glue",
          "PySpark",
          "Amazon Redshift",
          "Amazon S3",
          "AWS Lambda",
          "AWS Step Functions",
          "MLflow",
          "SageMaker Clarify",
          "LangChain",
          "LangGraph",
          "FAISS",
          "Chroma",
          "Python",
          "scikit-learn",
          "XGBoost",
          "Logistic regression",
          "PCA",
          "KMeans",
          "Docker"
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          "Developed modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL.",
          "Implemented backend services, stored procedures, and batch jobs to process high-volume claims and membership data.",
          "Refactored legacy code into modular components, reducing defects and accelerating delivery of regulatory changes.",
          "Translated CMS/state regulations into technical designs, sequence diagrams, and data contracts.",
          "Participated in code reviews, performance tuning, and deployments with onshore/offshore teams."
        ],
        "skills": [
          "Java",
          "PL/SQL",
          "SQL",
          "Git",
          "SVN",
          "Jenkins"
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          "Built backend components for FedEx eDD and enterprise systems, implementing business logic and data access layers.",
          "Developed REST/SOAP integrations and transformation pipelines for secure document and shipment workflows.",
          "Automated operational tasks with Java/SQL and scripting tools for log analysis and data reconciliation.",
          "Resolved production incidents and delivered fixes with regression test coverage."
        ],
        "skills": [
          "Java",
          "SQL",
          "REST",
          "SOAP"
        ]
      },
      {
        "title": "Programmer (Software Engineer)",
        "company": "Cognizant",
        "start_date": "Sep 2007",
        "end_date": "Aug 2010",
        "location": "Hyderabad, India",
        "bullets": [
          "Contributed to core HealthPAS Medicaid modules, implementing business rules and batch processes.",
          "Developed and optimized SQL/PL/SQL queries, procedures, and views for transactional workflows and reporting.",
          "Built integration utilities for data movement across claims processing and credentialing systems.",
          "Wrote unit/integration tests and fixed defects identified during system and UAT phases.",
          "Collaborated with BA/QA/infrastructure teams to resolve environment-specific issues and improve stability."
        ],
        "skills": [
          "SQL",
          "PL/SQL"
        ]
      }
    ],
    "education": [
      "Nizam College – B.Sc., Mathematics, Physics, Electronics (Sep 2003 – May 2007) | Hyderabad, India"
    ],
    "education_items": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ]
  },
  "plan": {
    "target_title": "Senior Machine Learning Engineer, Applied AI",
    "target_company": "Block",
    "sections_order": [
      "summary",
      "skills",
      "experience",
      "education",
      "certifications"
    ],
    "length_hint": "two_pages_ok",
    "experiences_plan": [
      {
        "profile_experience_index": 0,
        "include": true,
        "relevance_score": 0.96,
        "target_bullet_count": 12,
        "focus_skills": [
          "Large language models (LLMs)",
          "Generative AI product development",
          "RAG (Retrieval-Augmented Generation)",
          "Prompt engineering",
          "Prompt orchestration (LangChain, LangGraph)",
          "Agentic AI workflows",
          "LLM integration (AWS Bedrock)",
          "Vector search (FAISS, Chroma)",
          "Scalable ML systems design",
          "MLOps (training, evaluation, CI/CD, monitoring)",
          "AWS SageMaker (training, endpoints, batch/real-time)",
          "Experiment tracking (MLflow)",
          "Model monitoring and bias/drift (SageMaker Clarify)",
          "Data pipelines (AWS Glue, PySpark, Redshift, S3)",
          "AWS Step Functions & Lambda orchestration",
          "API design and data contracts for downstream systems",
          "Production deployment and SLOs",
          "Customer-facing ML features with measurable impact",
          "Risk scoring models (provider/patient) and fraud detection"
        ]
      },
      {
        "profile_experience_index": 1,
        "include": true,
        "relevance_score": 0.4,
        "target_bullet_count": 3,
        "focus_skills": [
          "Backend services at scale",
          "High-volume data processing (claims/membership)",
          "Java",
          "SQL/PLSQL",
          "Batch jobs and stored procedures",
          "Regulatory requirements to technical design",
          "Code reviews, performance tuning, deployments",
          "CI/CD (Jenkins, Git/SVN)"
        ]
      },
      {
        "profile_experience_index": 2,
        "include": true,
        "relevance_score": 0.3,
        "target_bullet_count": 2,
        "focus_skills": [
          "REST/SOAP integrations",
          "Secure document/shipment workflows",
          "Operational automation (Java/SQL scripting)",
          "Production incident resolution"
        ]
      },
      {
        "profile_experience_index": 3,
        "include": false,
        "relevance_score": 0.2,
        "target_bullet_count": 0,
        "focus_skills": []
      }
    ],
    "skills_plan": {
      "must_have_covered": [
        "Machine learning engineering (8+ years)",
        "Large Language Models (LLMs)",
        "Generative AI product development",
        "Scalable ML systems design and deployment",
        "MLOps (training, evaluation, CI/CD, monitoring, productionizing models)",
        "Cloud platforms (AWS/GCP/Azure) for high-scale production",
        "Building and shipping customer-facing ML features",
        "Data gathering and pipeline development for ML"
      ],
      "must_have_missing": [
        "LLM fine-tuning and integration",
        "Automation of customer support workflows"
      ],
      "nice_to_have_covered": [
        "Retrieval-Augmented Generation (RAG)",
        "Prompt orchestration / prompt engineering",
        "Platform engineering for internal developer customers",
        "Mentorship and technical leadership",
        "Strong cross-functional communication"
      ],
      "extra_profile_skills": [
        "Medicaid/Medicare domain expertise",
        "Healthcare claims analytics",
        "Fraud, Waste, and Abuse (FWA) analytics",
        "HIPAA-compliant data architectures",
        "EDI X12 5010",
        "ICD-10/CPT/HCPCS",
        "AWS Redshift",
        "AWS Glue",
        "PySpark",
        "Docker",
        "Kubernetes/EKS",
        "Kafka",
        "Java",
        "PL/SQL",
        "Unsupervised learning (PCA, KMeans)",
        "XGBoost",
        "scikit-learn",
        "Risk scoring models",
        "Network analysis"
      ]
    }
  },
  "tailored": {
    "full_name": "NARENDER SURABHI",
    "headline": "SENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "summary": "Senior Machine Learning Engineer specializing in applied Generative AI and scalable ML systems on AWS. 8+ years end-to-end ML ownership within 18+ years of software/data engineering, delivering production features across healthcare integrity and care management. Built and shipped LLM-powered RAG, agentic workflows, and fraud/risk models on SageMaker/Bedrock processing 116M+ claims annually. Full lifecycle: data pipelines (Glue/PySpark), training/evaluation (MLflow, Clarify), real-time/batch deployment, monitoring/SLOs, and API integration; mentor teams and contribute to AI standards and governance.",
    "skills": [
      {
        "name": "ML / AI & LLMs",
        "items": [
          "LLMs on AWS Bedrock",
          "RAG (FAISS, Chroma)",
          "Agentic workflows (LangChain, LangGraph)",
          "Prompt engineering & orchestration",
          "Supervised & unsupervised ML (logistic regression, XGBoost, PCA, KMeans)"
        ]
      },
      {
        "name": "Data Platforms & MLOps",
        "items": [
          "SageMaker (training, batch/real-time endpoints)",
          "Experiment tracking (MLflow)",
          "Monitoring & bias/drift (SageMaker Clarify)",
          "Pipelines: AWS Glue, PySpark; data marts in Redshift/S3",
          "Orchestration: Step Functions, Lambda; model SLOs & alerts"
        ]
      },
      {
        "name": "Cloud & Infrastructure",
        "items": [
          "AWS: S3, Redshift, EC2, CloudFormation",
          "Containers: Docker",
          "Streaming/ETL: Spark, Kafka",
          "CI/CD & VCS: Git, Bitbucket, Jenkins"
        ]
      },
      {
        "name": "Programming & APIs",
        "items": [
          "Python (pandas, NumPy, scikit-learn, PyTorch, TensorFlow, Keras)",
          "SQL, PL/SQL",
          "Java",
          "REST APIs, data contracts"
        ]
      },
      {
        "name": "Healthcare Domain",
        "items": [
          "Medicaid/Medicare claims",
          "FWA analytics & provider/patient risk",
          "HIPAA-compliant architectures",
          "EDI X12 5010, ICD-10, CPT/HCPCS"
        ]
      }
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          {
            "text": "Led AI/ML for Medicaid integrity and care-management products, owning architecture, implementation, and productionization of ML and GenAI features.",
            "source_experience_index": 0
          },
          {
            "text": "Designed and deployed LLM-powered RAG on AWS Bedrock to generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.",
            "source_experience_index": 0
          },
          {
            "text": "Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, data retrieval, and explanation generation to surface emerging FWA schemes.",
            "source_experience_index": 0
          },
          {
            "text": "Engineered HIPAA-compliant ML pipelines on SageMaker and AWS Glue (PySpark) processing 116M+ Medicaid claims annually with MLflow-based experiment tracking.",
            "source_experience_index": 0
          },
          {
            "text": "Operationalized supervised and unsupervised models for pre-pay/post-pay FWA detection, provider risk scoring, and patient risk stratification with batch and real-time endpoints.",
            "source_experience_index": 0
          },
          {
            "text": "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts to meet accuracy and latency targets.",
            "source_experience_index": 0
          },
          {
            "text": "Integrated vector search (FAISS, Chroma) and prompt orchestration (LangChain) to ground LLM outputs and improve narrative relevance.",
            "source_experience_index": 0
          },
          {
            "text": "Orchestrated training and inference workflows with AWS Step Functions and Lambda; containerized services with Docker for reliable deployments.",
            "source_experience_index": 0
          },
          {
            "text": "Designed APIs and data contracts exposing scores, risk tiers, and GenAI explanations to downstream SIU, audit, and care-management systems.",
            "source_experience_index": 0
          },
          {
            "text": "Mentored engineers and analysts on GenAI, MLOps, and Python best practices; contributed to AI roadmap, standards, and governance.",
            "source_experience_index": 0
          },
          {
            "text": "Patient Risk Scoring: Engineered features from claims, utilization, chronic conditions, demographics, and care gaps; deployed on SageMaker with Glue pipelines and Redshift/S3 data marts.",
            "source_experience_index": 0
          },
          {
            "text": "Provider Risk Scoring & Program Intelligence: Built provider/group risk models and architected a platform combining supervised models, unsupervised pattern mining, network analysis, and LLM narratives for statewide FWA detection; delivered real-time pre-pay fraud scoring (logistic regression + rules) with APIs and production monitoring.",
            "source_experience_index": 0
          }
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          {
            "text": "Developed modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL.",
            "source_experience_index": 1
          },
          {
            "text": "Implemented backend services, stored procedures, and batch jobs to process high-volume claims and membership data; participated in code reviews, performance tuning, and deployments.",
            "source_experience_index": 1
          },
          {
            "text": "Translated CMS/state regulations into technical designs, sequence diagrams, and data contracts; supported CI/CD with Git/SVN and Jenkins.",
            "source_experience_index": 1
          }
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          {
            "text": "Built backend components for FedEx eDD and enterprise systems, implementing business logic and data access layers; developed REST/SOAP integrations and transformation pipelines for secure document and shipment workflows.",
            "source_experience_index": 2
          },
          {
            "text": "Automated operational tasks with Java/SQL and scripting for log analysis and data reconciliation; resolved production incidents and delivered fixes with regression test coverage.",
            "source_experience_index": 2
          }
        ]
      }
    ],
    "education": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ],
    "resume_text": "NARENDER SURABHI\nSENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT\nOkemos, MI, USA 48864 | +1 (213) 254-8205 | surabhinarenderrao@gmail.com\nLinkedIn: https://www.linkedin.com/in/narendersurabhi | GitHub: https://github.com/narendersurabhi\n\nSummary\nSenior Machine Learning Engineer specializing in applied Generative AI and scalable ML systems on AWS. 8+ years end-to-end ML ownership within 18+ years of software/data engineering, delivering production features across healthcare integrity and care management. Built and shipped LLM-powered RAG, agentic workflows, and fraud/risk models on SageMaker/Bedrock processing 116M+ claims annually. Full lifecycle: data pipelines (Glue/PySpark), training/evaluation (MLflow, Clarify), real-time/batch deployment, monitoring/SLOs, and API integration; mentor teams and contribute to AI standards and governance.\n\nSkills\n- ML / AI & LLMs: LLMs on AWS Bedrock; RAG (FAISS, Chroma); Agentic workflows (LangChain, LangGraph); Prompt engineering & orchestration; Supervised & unsupervised ML (logistic regression, XGBoost, PCA, KMeans)\n- Data Platforms & MLOps: SageMaker (training, batch/real-time endpoints); Experiment tracking (MLflow); Monitoring & bias/drift (SageMaker Clarify); Pipelines: AWS Glue, PySpark; data marts in Redshift/S3; Orchestration: Step Functions, Lambda; model SLOs & alerts\n- Cloud & Infrastructure: AWS (S3, Redshift, EC2, CloudFormation); Containers: Docker; Streaming/ETL: Spark, Kafka; CI/CD & VCS: Git, Bitbucket, Jenkins\n- Programming & APIs: Python (pandas, NumPy, scikit-learn, PyTorch, TensorFlow, Keras); SQL, PL/SQL; Java; REST APIs, data contracts\n- Healthcare Domain: Medicaid/Medicare claims; FWA analytics & provider/patient risk; HIPAA-compliant architectures; EDI X12 5010, ICD-10, CPT/HCPCS\n\nExperience\nAcentra Health | Senior Machine Learning Engineer & AI Solutions Architect | Okemos, MI | Dec 2016 – Present\n- Led AI/ML for Medicaid integrity and care-management products, owning architecture, implementation, and productionization of ML and GenAI features.\n- Designed and deployed LLM-powered RAG on AWS Bedrock to generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.\n- Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, data retrieval, and explanation generation to surface emerging FWA schemes.\n- Engineered HIPAA-compliant ML pipelines on SageMaker and AWS Glue (PySpark) processing 116M+ Medicaid claims annually with MLflow-based experiment tracking.\n- Operationalized supervised and unsupervised models for pre-pay/post-pay FWA detection, provider risk scoring, and patient risk stratification with batch and real-time endpoints.\n- Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts to meet accuracy and latency targets.\n- Integrated vector search (FAISS, Chroma) and prompt orchestration (LangChain) to ground LLM outputs and improve narrative relevance.\n- Orchestrated training and inference workflows with AWS Step Functions and Lambda; containerized services with Docker for reliable deployments.\n- Designed APIs and data contracts exposing scores, risk tiers, and GenAI explanations to downstream SIU, audit, and care-management systems.\n- Mentored engineers and analysts on GenAI, MLOps, and Python best practices; contributed to AI roadmap, standards, and governance.\n- Patient Risk Scoring: Engineered features from claims, utilization, chronic conditions, demographics, and care gaps; deployed on SageMaker with Glue pipelines and Redshift/S3 data marts.\n- Provider Risk Scoring & Program Intelligence: Built provider/group risk models and architected a platform combining supervised models, unsupervised pattern mining, network analysis, and LLM narratives for statewide FWA detection; delivered real-time pre-pay fraud scoring (logistic regression + rules) with APIs and production monitoring.\n\nInfosys Limited | Senior Associate Consultant (Software Engineer) | Los Angeles, CA & Pune, India | Sep 2013 – Dec 2015\n- Developed modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL.\n- Implemented backend services, stored procedures, and batch jobs to process high-volume claims and membership data; participated in code reviews, performance tuning, and deployments.\n- Translated CMS/state regulations into technical designs, sequence diagrams, and data contracts; supported CI/CD with Git/SVN and Jenkins.\n\nSyntel Limited | Programmer Analyst (Software Engineer) | Pune, India | Aug 2010 – Sep 2013\n- Built backend components for FedEx eDD and enterprise systems, implementing business logic and data access layers; developed REST/SOAP integrations and transformation pipelines for secure document and shipment workflows.\n- Automated operational tasks with Java/SQL and scripting for log analysis and data reconciliation; resolved production incidents and delivered fixes with regression test coverage.\n\nEducation\n- Nizam College — B.Sc., Mathematics, Physics, Electronics (Sep 2003 – May 2007), Hyderabad, India\n\nCertifications\n- AWS Certified AI Practitioner (AIF-C01), Amazon Web Services, 2025\n- Data Science and Machine Learning: Making Data-Driven Decisions, Massachusetts Institute of Technology (MIT), 2022"
  },
  "qa": {
    "overall_match_score": 78.0,
    "must_have_coverage": {
      "Machine learning engineering (8+ years)": true,
      "Large Language Models (LLMs)": true,
      "Generative AI product development": true,
      "LLM fine-tuning and integration": false,
      "Scalable ML systems design and deployment": true,
      "MLOps (training, evaluation, CI/CD, monitoring, productionizing models)": true,
      "Cloud platforms (AWS/GCP/Azure) for high-scale production": true,
      "Building and shipping customer-facing ML features": true,
      "Data gathering and pipeline development for ML": true,
      "Automation of customer support workflows": false
    },
    "issues": [
      {
        "severity": "major",
        "message": "No explicit evidence of LLM fine-tuning; experience focuses on RAG, prompt orchestration, and Bedrock integration.",
        "location_hint": "Acentra Health bullets (LLM/RAG work)"
      },
      {
        "severity": "major",
        "message": "No examples of automating customer support workflows (chatbots, agent assist, case routing, deflection/CSAT/AHT metrics).",
        "location_hint": "Summary and Acentra Health role"
      },
      {
        "severity": "minor",
        "message": "ML CI/CD specifics (model registry, automated tests, deployment strategy, rollback/canary) are not detailed.",
        "location_hint": "Skills: Data Platforms & MLOps; Acentra Health bullets"
      },
      {
        "severity": "minor",
        "message": "LLM evaluation techniques and guardrails (hallucination tests, safety/PII filters, red-teaming) are not described.",
        "location_hint": "Summary and Acentra Health role"
      },
      {
        "severity": "minor",
        "message": "Experimentation/A-B testing for ML features not mentioned.",
        "location_hint": "Entire resume"
      },
      {
        "severity": "minor",
        "message": "Impact metrics are qualitative; lacks quantified outcomes (e.g., % time reduction, precision/recall, latency, throughput, cost savings).",
        "location_hint": "Acentra Health bullets"
      },
      {
        "severity": "minor",
        "message": "Cloud experience is AWS-centric; no mention of GCP/Azure.",
        "location_hint": "Skills: Cloud & Infrastructure"
      }
    ],
    "suggestions": [
      "If applicable, add concrete LLM fine-tuning projects on Bedrock (models used, datasets, techniques, eval metrics) and how they improved task performance vs. base models.",
      "Include a customer support automation example (agent assist, deflection bot, case routing, knowledge retrieval, summarization) with measurable impact (deflection rate, CSAT lift, AHT reduction).",
      "Detail ML CI/CD: model registry/governance, automated data/model tests, canary/blue-green deployments, rollback strategy, and tooling (e.g., SageMaker Pipelines/Projects, CodePipeline/Jenkins).",
      "Add LLM evaluation and guardrails: prompt eval harness, hallucination rate, toxicity/PII filtering, jailbreak/prompt-injection defenses, output monitoring and feedback loops.",
      "Mention online experimentation (A/B or interleaving) for ML/LLM features and the decision metrics used.",
      "Quantify outcomes: % reduction in investigator time, false positive/negative rate changes, latency/QPS, cost/performance optimizations (instance right-sizing, batch vs. realtime tradeoffs).",
      "Call out any multi-tenant/platform capabilities that serve multiple products/business units and how APIs/data contracts enabled reuse.",
      "If relevant, add exposure to GCP/Azure or note portability of your platform design to multi-cloud."
    ]
  },
  "job_id": "68f06d76-0290-4d7b-b16b-2434a95c7367"
}