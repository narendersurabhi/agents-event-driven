{
  "stage": "COMPLETED",
  "run_qa": true,
  "run_improver": true,
  "jd": {
    "role_title": "Senior Machine Learning Engineer",
    "company": "Replicant",
    "seniority_level": "Senior",
    "must_have_skills": [
      "Machine learning engineering",
      "ML infrastructure",
      "ML tooling",
      "Production ML systems",
      "Generative AI",
      "Large Language Models (LLMs)",
      "Natural Language Processing (NLP)",
      "Software development (5+ years)",
      "Experimentation to deployment of ML models",
      "Performance optimization",
      "Cross-functional collaboration"
    ],
    "nice_to_have_skills": [
      "Python",
      "PyTorch",
      "FAISS",
      "Elasticsearch",
      "Conversational AI / Voice AI",
      "Vector similarity search"
    ],
    "notes_for_resume": "- Highlight 5+ years building ML infrastructure/tooling or shipping ML-powered products; quantify reliability, latency, and cost improvements.\n- Showcase hands-on LLM/Generative AI and NLP work translating research into production systems for real users.\n- Detail end-to-end ownership: ideation, experimentation, implementation, deployment, and ongoing optimization.\n- Include experience with conversational AI/voice or contact center automation, with measurable outcomes (deflection rate, CSAT, AHT).\n- List relevant stack: Python, PyTorch, FAISS, Elasticsearch; mention vector search usage where applicable.\n- Emphasize collaboration with product and cross-functional teams; tie ML solutions to business goals.\n- Demonstrate leadership: setting technical direction, mentoring, driving innovation in ambiguous problem spaces.\n- Provide links to repos/demos/publications that evidence applied GenAI/LLM systems at scale."
  },
  "profile": {
    "full_name": "NARENDER SURABHI",
    "headline": "SENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "years_of_experience": 17.3,
    "core_skills": [
      "Generative AI",
      "Large Language Models (LLMs)",
      "Retrieval-Augmented Generation (RAG)",
      "Agentic AI",
      "Prompt Engineering",
      "Machine Learning",
      "Risk Analytics",
      "Fraud/Waste/Abuse (FWA) Detection",
      "Provider Risk Scoring",
      "Patient Risk Stratification",
      "Anomaly Detection",
      "Feature Engineering",
      "Model Deployment",
      "Model Monitoring",
      "MLOps",
      "Data Pipelines",
      "ETL/ELT",
      "Model Evaluation"
    ],
    "domain_expertise": [
      "Medicaid/Medicare",
      "Healthcare claims",
      "FWA analytics",
      "Provider network integrity",
      "Care management & outreach",
      "HIPAA",
      "EDI X12 5010",
      "ICD-10",
      "CPT",
      "HCPCS",
      "Membership & benefits",
      "SURS audits"
    ],
    "tools_and_tech": [
      "AWS SageMaker",
      "AWS Bedrock",
      "AWS Glue (PySpark)",
      "Amazon Redshift",
      "Amazon S3",
      "AWS Lambda",
      "AWS Step Functions",
      "SageMaker Clarify",
      "MLflow",
      "Python",
      "Pandas",
      "NumPy",
      "SciPy",
      "Scikit-learn",
      "XGBoost",
      "PyTorch",
      "TensorFlow/Keras",
      "FAISS",
      "Chroma",
      "LangChain",
      "LangGraph",
      "Docker",
      "Kubernetes/EKS",
      "Spark",
      "Kafka",
      "SQL",
      "PL/SQL",
      "Java",
      "REST APIs",
      "SOAP",
      "Git",
      "Bitbucket",
      "SVN",
      "Jenkins",
      "CloudFormation",
      "EC2"
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          "AI/ML lead for Medicaid integrity and care-management products, owning architecture, implementation, and productionization of ML and GenAI capabilities.",
          "Designed and deployed LLM-powered features on AWS Bedrock (RAG + vector search) to auto-generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.",
          "Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, data retrieval, and explanation generation.",
          "Engineered HIPAA-compliant ML pipelines on SageMaker and Glue (PySpark) processing 116M+ Medicaid claims annually with automated feature extraction and MLflow experiment tracking.",
          "Operationalized supervised and unsupervised models for pre-pay and post-pay FWA detection, provider risk scoring, and patient risk stratification; integrated outputs into SIU, audit, and care-management workflows.",
          "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts for accuracy, latency, and coverage.",
          "Designed APIs and data contracts exposing scores, risk tiers, and GenAI explanations to downstream systems; collaborated with product, engineering, clinical, and compliance teams.",
          "Mentored engineers and analysts on GenAI, MLOps, Python best practices, and experimentation; influenced AI roadmap, standards, and governance.",
          "Medicaid Patient Risk Scoring: engineered features from claims, utilization, chronic conditions, demographics, and care gaps; deployed on SageMaker with Glue/Redshift/S3; delivered ranked outreach lists and explanations.",
          "Medicaid Provider Risk Scoring: aggregated claim, member, and peer-comparison features; deployed on SageMaker with Glue/Redshift/S3; integrated into Program Intelligence and SIU workflows.",
          "Program Intelligence: combined supervised/unsupervised models, network analysis, and LLM narratives to detect FWA across large Medicaid populations.",
          "AuditStudio (North Dakota): built PCA and KMeans pipelines to score claims/providers for post-pay audit prioritization; delivered prioritized lists via Glue PySpark and Redshift/S3.",
          "ClaimsSure: developed pre-pay fraud scoring (logistic regression + rules) with end-to-end integration, scoring APIs, thresholds/overrides, and production monitoring."
        ],
        "skills": [
          "AWS Bedrock",
          "AWS SageMaker",
          "AWS Glue (PySpark)",
          "Amazon Redshift",
          "Amazon S3",
          "AWS Lambda",
          "AWS Step Functions",
          "SageMaker Clarify",
          "MLflow",
          "Python",
          "Pandas",
          "NumPy",
          "Scikit-learn",
          "XGBoost",
          "PyTorch",
          "TensorFlow/Keras",
          "FAISS",
          "Chroma",
          "LangChain",
          "LangGraph",
          "Docker",
          "Kubernetes/EKS",
          "REST APIs",
          "Jenkins",
          "Git/Bitbucket",
          "PCA",
          "KMeans",
          "Logistic Regression"
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          "Developed and enhanced modules for Medicaid encounter processing and Open Health Plus using Java, PL/SQL, and SQL.",
          "Built backend services, stored procedures, and batch jobs to process high-volume healthcare claims and membership data.",
          "Refactored legacy code into modular components, reducing defects and improving maintainability.",
          "Translated CMS/state regulations into technical designs, sequence diagrams, and data contracts.",
          "Participated in code reviews, performance tuning, and deployment planning with onshore/offshore teams using Git/SVN and Jenkins."
        ],
        "skills": [
          "Java",
          "SQL",
          "PL/SQL",
          "Jenkins",
          "Git",
          "SVN",
          "Batch Processing"
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          "Built and maintained backend components for FedEx eDD and related enterprise systems.",
          "Developed REST/SOAP integrations, validation logic, and transformation pipelines for document and shipment workflows.",
          "Created internal tools and utilities (Java/SQL and scripting) to automate operational tasks, log analysis, and data reconciliation.",
          "Analyzed production incidents, reproduced bugs, and delivered fixes with regression test coverage.",
          "Followed engineering best practices including version control, peer reviews, and release checklists."
        ],
        "skills": [
          "Java",
          "SQL",
          "REST",
          "SOAP",
          "Scripting",
          "Regression Testing",
          "Version Control"
        ]
      },
      {
        "title": "Programmer (Software Engineer)",
        "company": "Cognizant",
        "start_date": "Sep 2007",
        "end_date": "Aug 2010",
        "location": "Hyderabad, India",
        "bullets": [
          "Contributed to core modules of the HealthPAS Medicaid system, implementing business rules and batch processes.",
          "Developed and optimized SQL/PL/SQL queries, procedures, and views for transactional workflows, eligibility processing, and reporting.",
          "Built integration components and utilities to move data between claims processing systems and downstream analytics layers.",
          "Wrote unit and integration tests; assisted in test data setup and defect fixes during system and UAT phases.",
          "Collaborated with BA, QA, and infrastructure teams to resolve environment-specific issues and improve system stability."
        ],
        "skills": [
          "SQL",
          "PL/SQL",
          "Batch Processing",
          "Unit Testing",
          "Integration Testing"
        ]
      }
    ],
    "education": [
      "Nizam College – B.Sc., Mathematics, Physics, Electronics (Sep 2003 – May 2007), Hyderabad, India"
    ],
    "education_items": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ]
  },
  "plan": {
    "target_title": "Senior Machine Learning Engineer",
    "target_company": "Replicant",
    "sections_order": [
      "Header",
      "Summary",
      "Skills",
      "Experience",
      "Education",
      "Certifications",
      "Links"
    ],
    "length_hint": "two_pages_ok",
    "experiences_plan": [
      {
        "profile_experience_index": 0,
        "include": true,
        "relevance_score": 0.96,
        "target_bullet_count": 10,
        "focus_skills": [
          "Generative AI",
          "Large Language Models (LLMs)",
          "Retrieval-Augmented Generation (RAG)",
          "Vector similarity search",
          "FAISS",
          "Chroma",
          "LangChain",
          "LangGraph",
          "AWS Bedrock",
          "AWS SageMaker",
          "MLOps",
          "ML infrastructure",
          "ML tooling",
          "Production ML systems",
          "Python",
          "PyTorch",
          "Model deployment",
          "Experimentation to deployment",
          "Monitoring",
          "SageMaker Clarify (bias/drift)",
          "Performance optimization",
          "Latency and cost optimization",
          "Reliability/SLOs",
          "Data pipelines (Glue PySpark, Redshift, S3)",
          "APIs and data contracts",
          "Cross-functional collaboration",
          "Leadership and mentoring",
          "Healthcare/Medicaid domain and HIPAA"
        ]
      },
      {
        "profile_experience_index": 1,
        "include": true,
        "relevance_score": 0.45,
        "target_bullet_count": 3,
        "focus_skills": [
          "Software development",
          "Backend services",
          "High-volume data processing",
          "SQL/PL-SQL",
          "Performance tuning",
          "Data contracts",
          "Code quality and reviews",
          "CI/CD (Jenkins, Git/SVN)",
          "Cross-team collaboration"
        ]
      },
      {
        "profile_experience_index": 2,
        "include": true,
        "relevance_score": 0.3,
        "target_bullet_count": 2,
        "focus_skills": [
          "Backend engineering",
          "REST/SOAP integrations",
          "Operational tooling/automation",
          "Production incident analysis",
          "Version control and release processes"
        ]
      },
      {
        "profile_experience_index": 3,
        "include": true,
        "relevance_score": 0.25,
        "target_bullet_count": 2,
        "focus_skills": [
          "SQL/PL-SQL",
          "Batch processing",
          "Data integration",
          "Testing (unit/integration)",
          "Collaboration with BA/QA/infrastructure"
        ]
      }
    ],
    "skills_plan": {
      "must_have_covered": [
        "Machine learning engineering",
        "ML infrastructure",
        "ML tooling",
        "Production ML systems",
        "Generative AI",
        "Large Language Models (LLMs)",
        "Natural Language Processing (NLP)",
        "Software development (5+ years)",
        "Experimentation to deployment of ML models",
        "Performance optimization",
        "Cross-functional collaboration"
      ],
      "must_have_missing": [],
      "nice_to_have_covered": [
        "Python",
        "PyTorch",
        "FAISS",
        "Vector similarity search"
      ],
      "extra_profile_skills": [
        "AWS SageMaker",
        "AWS Bedrock",
        "MLflow",
        "LangChain",
        "LangGraph",
        "MLOps",
        "AWS Glue (PySpark)",
        "Amazon Redshift",
        "Amazon S3",
        "AWS Step Functions",
        "Docker",
        "Kubernetes/EKS",
        "TensorFlow/Keras",
        "Scikit-learn",
        "XGBoost",
        "Spark",
        "Kafka",
        "SQL",
        "REST APIs",
        "Jenkins",
        "Git/Bitbucket",
        "Risk Analytics",
        "Fraud/Waste/Abuse (FWA) Detection",
        "HIPAA"
      ]
    }
  },
  "tailored": {
    "full_name": "NARENDER SURABHI",
    "headline": "SENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT",
    "location": "Okemos, MI, USA 48864",
    "phone": "+1 (213) 254-8205",
    "email": "surabhinarenderrao@gmail.com",
    "linkedin_url": "https://www.linkedin.com/in/narendersurabhi",
    "github_url": "https://github.com/narendersurabhi",
    "summary": "Senior Machine Learning Engineer and Generative AI/MLOps architect with 17+ years across software and data delivering production ML systems end to end. Built LLM-powered RAG and agentic workflows on AWS (SageMaker, Bedrock) with vector search (FAISS) and robust MLOps, operating at Medicaid scale (116M+ claims/year). Proven in ML infrastructure/tooling, monitoring (Clarify), performance and reliability SLOs, and cross-functional delivery with product, engineering, and clinical stakeholders.",
    "skills": [
      {
        "name": "ML / AI & LLMs",
        "items": [
          "Generative AI; LLMs (AWS Bedrock)",
          "RAG; Vector search (FAISS, Chroma)",
          "LangChain, LangGraph; Agentic workflows",
          "NLP; Explainability & narratives",
          "Supervised & unsupervised ML",
          "Model evaluation & monitoring (SageMaker Clarify)"
        ]
      },
      {
        "name": "Data Platforms & MLOps",
        "items": [
          "AWS SageMaker; MLflow experiments",
          "Pipelines: Glue (PySpark), Redshift, S3",
          "AWS Step Functions & Lambda",
          "Docker; Kubernetes/EKS",
          "CI/CD (Jenkins); Git/Bitbucket",
          "Monitoring, SLOs, alerting"
        ]
      },
      {
        "name": "Languages & Frameworks",
        "items": [
          "Python",
          "PyTorch; TensorFlow/Keras",
          "Scikit-learn; XGBoost",
          "SQL; PL/SQL",
          "Java",
          "Spark; Kafka"
        ]
      },
      {
        "name": "Systems & APIs",
        "items": [
          "REST APIs; Data contracts",
          "Feature engineering; ETL/ELT",
          "Batch processing",
          "CloudFormation",
          "Version control (Git/Bitbucket/SVN)",
          "HIPAA-compliant ML systems"
        ]
      }
    ],
    "experience": [
      {
        "title": "Senior Machine Learning Engineer & AI Solutions Architect",
        "company": "Acentra Health",
        "start_date": "Dec 2016",
        "end_date": "Present",
        "location": "Okemos, MI",
        "bullets": [
          {
            "text": "Led AI/ML for Medicaid integrity and care-management products, owning architecture, experimentation, deployment, and operations of production ML and GenAI capabilities.",
            "source_experience_index": 0
          },
          {
            "text": "Shipped LLM-powered RAG features on AWS Bedrock with vector similarity search (FAISS/Chroma) to auto-generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.",
            "source_experience_index": 0
          },
          {
            "text": "Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, tool use, data retrieval, and explanation generation.",
            "source_experience_index": 0
          },
          {
            "text": "Engineered HIPAA-compliant ML pipelines on SageMaker and Glue (PySpark) processing 116M+ Medicaid claims annually; automated feature extraction and tracked experiments with MLflow.",
            "source_experience_index": 0
          },
          {
            "text": "Operationalized supervised and unsupervised models (e.g., logistic regression, XGBoost, PCA, KMeans) for pre-pay/post-pay FWA detection and risk scoring; integrated outputs via REST APIs into SIU, audit, and care-management workflows.",
            "source_experience_index": 0
          },
          {
            "text": "Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts for accuracy, latency, and coverage.",
            "source_experience_index": 0
          },
          {
            "text": "Optimized model serving and data pipelines on SageMaker/Step Functions to meet reliability and latency targets at scale.",
            "source_experience_index": 0
          },
          {
            "text": "Designed data contracts and versioned APIs exposing scores, risk tiers, and GenAI explanations to downstream systems; collaborated with product, engineering, clinical, and compliance stakeholders.",
            "source_experience_index": 0
          },
          {
            "text": "Mentored engineers and analysts on GenAI, MLOps, and Python best practices; influenced AI roadmap, standards, and governance.",
            "source_experience_index": 0
          },
          {
            "text": "Delivered Patient Risk Scoring and Provider Risk Scoring on SageMaker (Glue/Redshift/S3), Program Intelligence for Medicaid FWA, pre-pay ClaimsSure (logistic regression + rules), and post-pay AuditStudio (PCA/KMeans) for audit prioritization.",
            "source_experience_index": 0
          }
        ]
      },
      {
        "title": "Senior Associate Consultant (Software Engineer)",
        "company": "Infosys Limited",
        "start_date": "Sep 2013",
        "end_date": "Dec 2015",
        "location": "Los Angeles, CA & Pune, India",
        "bullets": [
          {
            "text": "Built backend services, stored procedures, and batch jobs in Java, SQL, and PL/SQL to process high-volume Medicaid encounters and membership data.",
            "source_experience_index": 1
          },
          {
            "text": "Refactored legacy modules into modular components, reducing defects and improving maintainability; performed performance tuning and code reviews.",
            "source_experience_index": 1
          },
          {
            "text": "Collaborated with onshore/offshore teams to translate CMS/state regulations into technical designs and data contracts; managed CI/CD with Jenkins and Git/SVN.",
            "source_experience_index": 1
          }
        ]
      },
      {
        "title": "Programmer Analyst (Software Engineer)",
        "company": "Syntel Limited",
        "start_date": "Aug 2010",
        "end_date": "Sep 2013",
        "location": "Pune, India",
        "bullets": [
          {
            "text": "Developed REST/SOAP integrations, validation logic, and transformation pipelines for FedEx eDD and related enterprise workflows; automated operations with internal tools (Java/SQL, scripting).",
            "source_experience_index": 2
          },
          {
            "text": "Investigated production incidents, reproduced bugs, and shipped fixes with regression tests; adhered to version control and release checklists.",
            "source_experience_index": 2
          }
        ]
      },
      {
        "title": "Programmer (Software Engineer)",
        "company": "Cognizant",
        "start_date": "Sep 2007",
        "end_date": "Aug 2010",
        "location": "Hyderabad, India",
        "bullets": [
          {
            "text": "Contributed to core modules of the HealthPAS Medicaid system, implementing business rules and batch processes; optimized SQL/PL/SQL for transactional workflows.",
            "source_experience_index": 3
          },
          {
            "text": "Built integration components, unit and integration tests, and test data utilities; partnered with BA/QA/infrastructure to resolve environment issues and improve stability.",
            "source_experience_index": 3
          }
        ]
      }
    ],
    "education": [
      {
        "institution": "Nizam College",
        "degree": "B.Sc., Mathematics, Physics, Electronics",
        "start_date": "Sep 2003",
        "end_date": "May 2007",
        "location": "Hyderabad, India"
      }
    ],
    "certifications": [
      {
        "name": "AWS Certified AI Practitioner (AIF-C01)",
        "issuer": "Amazon Web Services",
        "year": "2025"
      },
      {
        "name": "Data Science and Machine Learning: Making Data-Driven Decisions",
        "issuer": "Massachusetts Institute of Technology (MIT)",
        "year": "2022"
      }
    ],
    "resume_text": "NARENDER SURABHI\nSENIOR MACHINE LEARNING ENGINEER | GENERATIVE AI & MLOPS ARCHITECT\nOkemos, MI, USA 48864 | +1 (213) 254-8205 | surabhinarenderrao@gmail.com\nLinkedIn: https://www.linkedin.com/in/narendersurabhi | GitHub: https://github.com/narendersurabhi\n\nSUMMARY\nSenior Machine Learning Engineer and Generative AI/MLOps architect with 17+ years across software and data delivering production ML systems end to end. Built LLM-powered RAG and agentic workflows on AWS (SageMaker, Bedrock) with vector search (FAISS) and robust MLOps, operating at Medicaid scale (116M+ claims/year). Proven in ML infrastructure/tooling, monitoring (Clarify), performance and reliability SLOs, and cross-functional delivery with product, engineering, and clinical stakeholders.\n\nSKILLS\n- ML / AI & LLMs: Generative AI; LLMs (AWS Bedrock); RAG; Vector search (FAISS, Chroma); LangChain, LangGraph; Agentic workflows; NLP; Supervised & unsupervised ML; Model evaluation & monitoring (SageMaker Clarify)\n- Data Platforms & MLOps: AWS SageMaker; MLflow experiments; Pipelines: Glue (PySpark), Redshift, S3; AWS Step Functions & Lambda; Docker; Kubernetes/EKS; CI/CD (Jenkins); Monitoring, SLOs, alerting\n- Languages & Frameworks: Python; PyTorch; TensorFlow/Keras; Scikit-learn; XGBoost; SQL; PL/SQL; Java; Spark; Kafka\n- Systems & APIs: REST APIs; Data contracts; Feature engineering; ETL/ELT; Batch processing; CloudFormation; Version control (Git/Bitbucket/SVN); HIPAA-compliant ML systems\n\nEXPERIENCE\nAcentra Health — Senior Machine Learning Engineer & AI Solutions Architect | Okemos, MI | Dec 2016 – Present\n- Led AI/ML for Medicaid integrity and care-management products, owning architecture, experimentation, deployment, and operations of production ML and GenAI capabilities.\n- Shipped LLM-powered RAG features on AWS Bedrock with vector similarity search (FAISS/Chroma) to auto-generate fraud, provider risk, and patient risk narratives, reducing reviewer investigation time.\n- Built agentic AI workflows (LangGraph + Bedrock) for multi-step fraud pattern discovery, tool use, data retrieval, and explanation generation.\n- Engineered HIPAA-compliant ML pipelines on SageMaker and Glue (PySpark) processing 116M+ Medicaid claims annually; automated feature extraction and tracked experiments with MLflow.\n- Operationalized supervised and unsupervised models (e.g., logistic regression, XGBoost, PCA, KMeans) for pre-pay/post-pay FWA detection and risk scoring; integrated outputs via REST APIs into SIU, audit, and care-management workflows.\n- Implemented monitoring for drift, bias, and performance using SageMaker Clarify and custom dashboards; defined SLOs and alerts for accuracy, latency, and coverage.\n- Optimized model serving and data pipelines on SageMaker/Step Functions to meet reliability and latency targets at scale.\n- Designed data contracts and versioned APIs exposing scores, risk tiers, and GenAI explanations to downstream systems; collaborated with product, engineering, clinical, and compliance stakeholders.\n- Mentored engineers and analysts on GenAI, MLOps, and Python best practices; influenced AI roadmap, standards, and governance.\n- Delivered Patient Risk Scoring and Provider Risk Scoring on SageMaker (Glue/Redshift/S3), Program Intelligence for Medicaid FWA, pre-pay ClaimsSure (logistic regression + rules), and post-pay AuditStudio (PCA/KMeans) for audit prioritization.\n\nInfosys Limited — Senior Associate Consultant (Software Engineer) | Los Angeles, CA & Pune, India | Sep 2013 – Dec 2015\n- Built backend services, stored procedures, and batch jobs in Java, SQL, and PL/SQL to process high-volume Medicaid encounters and membership data.\n- Refactored legacy modules into modular components, reducing defects and improving maintainability; performed performance tuning and code reviews.\n- Collaborated with onshore/offshore teams to translate CMS/state regulations into technical designs and data contracts; managed CI/CD with Jenkins and Git/SVN.\n\nSyntel Limited — Programmer Analyst (Software Engineer) | Pune, India | Aug 2010 – Sep 2013\n- Developed REST/SOAP integrations, validation logic, and transformation pipelines for FedEx eDD and related enterprise workflows; automated operations with internal tools (Java/SQL, scripting).\n- Investigated production incidents, reproduced bugs, and shipped fixes with regression tests; adhered to version control and release checklists.\n\nCognizant — Programmer (Software Engineer) | Hyderabad, India | Sep 2007 – Aug 2010\n- Contributed to core modules of the HealthPAS Medicaid system, implementing business rules and batch processes; optimized SQL/PL/SQL for transactional workflows.\n- Built integration components, unit and integration tests, and test data utilities; partnered with BA/QA/infrastructure to resolve environment issues and improve stability.\n\nEDUCATION\n- Nizam College — B.Sc., Mathematics, Physics, Electronics (Sep 2003 – May 2007), Hyderabad, India\n\nCERTIFICATIONS\n- AWS Certified AI Practitioner (AIF-C01), Amazon Web Services, 2025\n- Data Science and Machine Learning: Making Data-Driven Decisions, Massachusetts Institute of Technology (MIT), 2022\n\nLINKS\n- LinkedIn: https://www.linkedin.com/in/narendersurabhi\n- GitHub: https://github.com/narendersurabhi"
  },
  "qa": {
    "overall_match_score": 85.0,
    "must_have_coverage": {
      "Machine learning engineering": true,
      "ML infrastructure": true,
      "ML tooling": true,
      "Production ML systems": true,
      "Generative AI": true,
      "Large Language Models (LLMs)": true,
      "Natural Language Processing (NLP)": true,
      "Software development (5+ years)": true,
      "Experimentation to deployment of ML models": true,
      "Performance optimization": true,
      "Cross-functional collaboration": true
    },
    "issues": [
      {
        "severity": "minor",
        "message": "Claim about optimizing model serving and pipelines for latency/reliability is not explicitly evidenced in the truth-source profile; consider adding concrete evidence or adjusting wording.",
        "location_hint": "Acentra Health experience bullet: \"Optimized model serving and data pipelines on SageMaker/Step Functions to meet reliability and latency targets at scale.\""
      },
      {
        "severity": "minor",
        "message": "NLP capability is implied through LLM narrative generation but not explicitly listed as a core skill in the truth-source; clarify concrete NLP methods/tools to avoid ambiguity.",
        "location_hint": "Summary and Skills sections referencing NLP"
      }
    ],
    "suggestions": [
      "Quantify impact: add concrete reliability/latency/cost metrics (e.g., p95 latency, throughput, uptime SLOs, infra cost reductions, investigator time reduction %).",
      "Detail performance optimization techniques actually used (e.g., batching/async, caching, model quantization, vector index tuning, autoscaling, concurrency controls).",
      "Strengthen NLP evidence: list specific methods/tools (tokenization/embeddings, retrieval metrics like Recall@k/MRR, prompt eval frameworks, text quality metrics).",
      "Add business outcomes for GenAI features (e.g., audit yield lift, false-positive reduction, reviewer AHT reduction).",
      "If applicable, note any Elasticsearch/OpenSearch experience or a quick POC to show readiness alongside FAISS/Chroma.",
      "Replicant context: highlight any conversational AI or voice stack exposure (ASR/TTS, dialog policy, contact center KPIs like deflection rate, CSAT, AHT) or build a small demo to showcase capability.",
      "Provide links to public repos/demos or architecture write-ups of your LLM/RAG systems at scale (sanitized notebooks, diagrams, eval dashboards).",
      "Specify vector search scale and configuration (number of vectors, FAISS index type, embedding models) and observed retrieval performance."
    ]
  },
  "job_id": "3ffd4102-6766-43df-ae3f-c2c87c76bce1"
}